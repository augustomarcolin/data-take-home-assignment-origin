---
title: "Take Home Assignment - Origin Financial"
author: "Augusto Marcolin"
date: "July 19, 2021"
output: rmdformats::"readthedown"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, echo = FALSE)

library(dplyr)
library(tidyr)
library(stringr)
library(forcats)
library(testthat)
library(skimr)
library(ggplot2)
library(cowplot)
library(leaflet)
library(knitr)
library(kableExtra)
library(corrplot)
library(purrr)
library(factoextra)
#---- reading data ----

#raw
raw_users_db <- read.csv('../data/raw/users.csv') %>% 
  as_tibble()

raw_transaction_db <- read.csv('../data/raw/transactions.csv') %>% 
  as_tibble()

#clean

db_users <- readRDS('../data/processed/user_db.RDS') %>% 
  mutate(
    age_at = lubridate::time_length(difftime(created_at, date_of_birth), "years") #extracting age
  )

db_transactions <- readRDS('../data/processed/transaction_db.RDS')

# shapfile states
states <- tigris::states(cb=T)

db_train <- readRDS('../data/processed/db_train.RDS')

```

# Overview

This report has the goal of show all process developed to analyze the data challenge proposed by the Origin Financial team. It's organized in four main sessions:

The first session will be `Engineering Raw Data` where I'will describe all the steps needed to clean raw data. The following step, `Exploratory Data Analysis` has some descriptive analysis about the data. At this point I'll guide my analysis to data clustering based on RFM (Recency Frequency and Monetary). After that I'll show the clustering analysis at session `Clustering` and some insigths based on it. Finally, I have some notes and future ideas further some conclusion about the challenge.


# Engineering Raw Data

Before starting the data analysis, let's do a quickly review at available data sets and raise needs of pre-engineering.

## Customers

```{r}
glimpse(raw_users_db)
```

In a quick overview, it's possibly to note that variable `created_at` and `date_of_birth` should be modified to timestamp and date, respectivily. Also, we can note that all missing data are represented by empty character space and it will be replaced by `NA`.

The variables `state` and `city` has some strange characters like this: `<img src='#' onerror=alert('xss') />` I presume that this behavior is caused by a css operator and it'll be replaced by `NA`.

The variable `id` it's lowercase, while in the transactions data it's uppercased, so it'll be replaced by uppercase.

## Transactions

```{r}
glimpse(raw_transaction_db)
```
The transaction data doesn't so much engineering to do. It's just change timestamp and date types and replace empty spaces by `NA`. I also, replaced `.` by `_` in some variable names.

# Exploratory Data Analysis

The exploratory data analysis it's divides

```{r}
skim(db_users)
```
At this simple description about the dataset it's possibly to note that age has a outlier that will be replaced by `NA`. Also, the great number of missing data in the variable gender, turning it almost useless in the data analysis.


## Univariate Analysis

### Age

The customers age distribution are concentraded between the range 30 - 50 years as shown bellow:

```{r}
db_users %>% 
  filter(age_at <= 100) %>% 
  ggplot(aes(x = age_at)) +
  geom_histogram(fill = '#ed2f5b', alpha = 0.6) +
  theme_bw()
```

Maybe this variable could bea good one to use in the clustering process.

### State

The geographical distribuiton of customer are really dense in the California State (31%) followed by MD(11.1%) add NC/NY tied with (7.8%). It's important to note that more than 22% of the customers has no state information.

```{r}

merge_db <- db_users %>% 
  count(state) %>% 
  mutate(
    perc = round(n / sum(n) * 100, digits = 2)
  ) %>% 
  arrange(desc(n)) %>% 
  right_join(states, by = c("state" = "STUSPS")) %>% 
  sf::st_as_sf() %>% 
  mutate(
    label = sprintf("State: %s
                    Percent: %s", state,perc)
  )

pal <- colorNumeric("Reds", domain=merge_db$perc)


leaflet() %>% 
  addProviderTiles("CartoDB.Positron") %>%
  setView(-98.483330, 38.712046, zoom = 4) %>% 
  addPolygons(data = merge_db , 
              label = ~label,
              fillColor = ~pal(merge_db$perc), 
              fillOpacity = 0.7, 
              weight = 0.2, 
              smoothFactor = 0.2,
              highlightOptions = highlightOptions(color        = "white",
                                                  weight       = 2,
                                                  bringToFront = TRUE)) %>%
  addLegend(pal = pal, 
            values = merge_db$perc, 
            position = "bottomright", 
            title = "Household %")

```


## Users Transactions

Looking to the user transactions, I note a tiny number of different customers, just 84. Some of them (almost 20%) has more than one account, but as we expecte to analysi customer behavior over account behaviour I'll treat them as the same customer.

```{r}
db_transactions %>% 
  select(user_id, account_id) %>% 
  distinct() %>% 
  count(user_id, sort = T) %>% 
  count(n) %>% 
  mutate(
    perc = round(nn / sum(nn), digits = 4) * 100
  ) %>% 
  kable(col.names = c("Number of Accounts", "Number of Customers", "% of Customers")) %>% 
  kable_styling()

```

At this point it's really important to say that just 84 customers to do the cluster analysis could be a problem for a bunch of reasos as like:

- Some algorithms won't provide robust results under small samples

- The cluster interpretation could be a little messy.

- The pattern recognition it's hard to do

Sad that i'll develop my analysis and won't

### Type of transacions

```{r}
db_transactions %>% 
  count(type) %>% 
  mutate(
    perc = n / sum(n) 
  ) %>% 
  arrange(desc(n))  %>% 
  ggplot(aes(x = type, y = perc, label = scales::percent(perc))) +
  geom_bar(stat = 'identity', fill = '#ed2f5b') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(x = 'Transaction Type', y = "Percent") +
  geom_text(position = position_dodge(width = .9), vjust = -0.5, size = 4) +
  theme_bw()
```


Analysing the type of transactions we can note that has a mix of too different transactions. Income, Expense and Transfer, as I'll show in the next steps, it will be treated separatelly to do the clustering analysis.


```{r}
db_transactions %>% 
  mutate(amount = abs(amount)) %>% 
  ggplot(aes(x = amount, fill = type)) +
  geom_histogram() +
  facet_wrap(~type, scales = 'free') +
  theme_bw()

```

The amount money transactions types has a strange behaviour having low variety of values. Transfer for example has just the value 25. It's something that could affect the behavior of clusterig analysis.

```{r}
db_transactions %>% 
  ungroup() %>% 
  mutate(
    date = as.Date(date)
    ) %>% 
  group_by(date, type) %>% 
  summarise(
    n_transactions = n(),
    amount = sum(abs(amount))
  ) %>% 
  #filter(amount <= quantile(.$amount, 0.99), amount >= quantile(.$amount, 0.01)) %>% 
  pivot_longer(cols = c(-date,-type)) %>% 
  ggplot(aes(x = date, y = value, color = type)) +
  geom_line() +
  facet_wrap(~name, scales = 'free')+
  theme_bw()

```

Looking to number and amount of transactions per day by expenses, transfer and income it's possibly to note that the days 2021-06-15 (income and expense) and 2021-06-16 (income) has a lot more transactions compare to other days. Expense category it's almost 10x the median for the period and for income it's mre than 10x.

I don't know if this strange behavior comes from a selection bias or if this is from the data. I'll presume that this behavior is a normal one.


### Transactions Category

Looking the transactions category we can note that we have a lot of missing ones, but part of that is caused by income transactions. 

```{r}
db_transactions %>% 
  select(starts_with("extra_fields_category")) %>% 
  group_by_all() %>% 
  count(sort = T)  %>% 
  ungroup() %>% 
  mutate(
    perc = round(n/sum(n), digits = 4) * 100
  ) %>% 
  kable() %>% 
  kable_styling()

```

Almost 20% of transactions came from travel category, divided into taxi (Uber) and Airlines and Aviation.

Food and drink represent 25% divided in restaurants like coffe shop and fast foods.

Also has some transactions repesented by recreation and shops ans some transfer between accounts


### Merchant Name

```{r}
#----- *** extra_field merchant name ----

db_transactions %>% 
  filter(type == 'expense') %>% 
  count(extra_fields_merchant_name, sort = T) %>% 
  mutate(
    perc = round(n / sum(n) , digits = 2),
    extra_fields_merchant_name = fct_reorder(as_factor(extra_fields_merchant_name), perc, .desc = T), 
  ) %>% 
  arrange(desc(n))  %>% 
  ggplot(aes(x = extra_fields_merchant_name, y = perc, label = scales::percent(perc))) +
  geom_bar(stat = 'identity', fill = '#ed2f5b') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(x = 'Transaction Type', y = "Percent") +
  geom_text(position = position_dodge(width = .9), vjust = -0.5, size = 4) +
  theme_bw()

```

Looking deeper to the expense types and merchant names, we can see at the top Uber, McDonalds, starbaucks and so on.

### Channel Transactions

```{r}
db_transactions %>% 
  filter(type == 'expense') %>% 
  count(extra_fields_payment_channel, sort = T) %>% 
  mutate(
    perc = round(n / sum(n) , digits = 2),
    extra_fields_payment_channel = fct_reorder(as_factor(extra_fields_payment_channel), perc, .desc = T)
  ) %>% 
  arrange(desc(n))  %>% 
  ggplot(aes(x = extra_fields_payment_channel, y = perc, label = scales::percent(perc))) +
  geom_bar(stat = 'identity', fill = '#ed2f5b') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(x = 'Transaction Type', y = "Percent") +
  geom_text(position = position_dodge(width = .9), vjust = -0.5, size = 4) +
  theme_bw()
```

The preferencial channel to expenses is in store(73%). Would be interesting if we had some information abou online channels as app payment, website shop e etc.

### Payment Methods

```{r}
db_transactions %>% 
  count(extra_fields_payment_meta_payment_method, sort = T) %>% 
  mutate(
    perc = round(n / sum(n) , digits = 2)
  ) %>% 
  arrange(desc(n))  %>% 
  ggplot(aes(x = extra_fields_payment_meta_payment_method, y = perc, label = scales::percent(perc))) +
  geom_bar(stat = 'identity', fill = '#ed2f5b') +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(x = 'Transaction Type', y = "Percent") +
  geom_text(position = position_dodge(width = .9), vjust = -0.5, size = 4) +
  theme_bw()

```

By payment methods we have just 4% of transactions with this data, it's almost useless to the analysis.

## RFM Transformation

After this exploratory analysis about variables and looking to a solution to clustering problem . I decided transform the transactional data into recency frequency and monetary value for the tree types of transactions: Expense, Income and Transfer.

After this transformation our dataset looks like this:

```{r}
glimpse(db_train)
```

Just 84 datapoints (customers) and 33 variables. I drop the recency variables because I tougth that itsn't the goal of the analysis explore "how much time the customer doens't have any transaction".

### Expense vs Income

Firstly, analysing the behavior of the amount mean of transactions in expenses and income we can note some behaviours.

```{r}
db_train %>% 
  ggplot(aes(x = amount_mean_expense, y = amount_mean_income)) + 
  geom_jitter(color = '#ed2f5b', size = 2) +
  theme_bw()

```

Note that some customer has high income mean and low expense mean, while we have others that expend more than earn. This is a good expoiler about the clustering.

It's important to note the outlier that expend much more than earn, I will keep this customer in analysis because it's a different behaviour that could be more representative if we have more data.

### Expense Vs Income Vs Age

Adding the variable age to our analysis, it's possibly to note that it doesn't affect the behavior of income and expense, so this variable wouldn't be useful in the cluster analysis.

```{r}
db_train %>%
  select(age_at, amount_mean_income, amount_mean_expense) %>% 
  pivot_longer(cols = c(amount_mean_income, amount_mean_expense), names_to = 'amount', values_to = "value") %>% 
  ggplot(aes(x = value, y = age_at)) + 
  geom_point(color = '#ed2f5b', size = 2) +
  facet_wrap(~amount) +
  theme_bw()

```


### Expense vs Income vs Transfer

Transfer mean amount it's another variable that doesn't affect the income and expense. As shown bellow:

```{r}
db_train %>%
  select(amount_mean_transfer, amount_mean_income, amount_mean_expense) %>% 
  pivot_longer(cols = c(amount_mean_income, amount_mean_expense), names_to = 'amount', values_to = "value") %>% 
  ggplot(aes(x = value, y = amount_mean_transfer)) + 
  geom_point(color = '#ed2f5b', size = 2) +
  facet_wrap(~amount) +
  theme_bw()

```


### Relationship between categorys of expenses

Looking to the correlation between category expenses it's possibly to note that every transaction has a high correlation. This analysis isn't so conclusive because we have just 13 customers with expenses categories. 

Also, I will try to do a cluster with this datapoints, the main ideia is to show my way of thinking the problem than try to interpret something. Because just 13 customer isn't enough data to any analysis.

```{r}
category_features2 <-  db_transactions %>% 
  filter(type == 'expense', !(extra_fields_category_0 %in% c("Transfer", "Payment"))) %>% 
  select(user_id, extra_fields_category_0, amount, date) %>% 
  filter(!is.na(extra_fields_category_0)) %>% 
  mutate(
    date = as.Date(date),
  ) %>% 
  group_by(user_id, date, extra_fields_category_0) %>% 
  summarise(
    n_transactions = n(),
    amount = sum(abs(amount))
  ) %>% 
  group_by(user_id, extra_fields_category_0) %>% 
  summarise(
    n_transactions = sum(n_transactions),
    amount = sum(amount)
  ) %>% 
  ungroup() %>% 
  mutate(amount_mean = amount/n_transactions) %>% 
  pivot_wider(names_from = extra_fields_category_0, values_from = c(n_transactions, amount, amount_mean)) %>% 
  janitor::clean_names() %>% 
  mutate_if(is.integer, as.numeric) %>% 
  mutate_if(is.numeric, ~if_else(is.na(.), 0, .))


cor_db <- category_features2 %>% 
  select_at(vars(starts_with('amount_mean'))) %>% 
  cor()

corrplot(cor_db,method = 'number', type="upper", order="hclust", hclust.method = 'average')  
  
```

# Clustering

At the clustering analysis my goal is to made two type of clusters, one based on incomes and expenses and another one based on the categories of expense. I think this way could give us some conclusions about the data.

It's important to say that I use just one method of clustering called kmeans, it's based on centroid distances. This choice was made because the datasets has few datapoints and I would like to maintain the analysis as simple as possibly.

At the beggining of very clustering I will do a analysis to determine the optimal number of cluster, after that I will run the cluster analysis and made some insigths about the clusters responses.

### Expense vs Income

```{r}
db_train_pad <- db_train %>% 
  mutate_if(is.numeric, ~((. - mean(., na.rm = T))/sd(., na.rm = T))) 

#---- expense + income ----

#---- * number clusters ----

n_cluster_expense_income <- map(.x = c("silhouette", "wss", "gap_stat"),
      .f = ~fviz_nbclust(db_train_pad %>% select(amount_mean_income, amount_mean_expense),
                         kmeans,
                         .x)
  )

plot_grid(n_cluster_expense_income[[1]] + labs(title = "Silhouette"),
          n_cluster_expense_income[[2]] + labs(title = "Elbow"),
          n_cluster_expense_income[[3]] + labs(title = "Gap"), nrow = 1)
```

```{r}

#---- * clusters ----
cluster_expense_income <- db_train_pad %>% select(amount_mean_income, amount_mean_expense) %>% 
  kmeans(centers = 4, nstart = 25)

#---- * descriptive ----
db_expense_income <- db_train %>% 
  select(amount_mean_expense, amount_mean_income) %>% 
  mutate(
    cluster = as.factor(cluster_expense_income$cluster)
  )

db_expense_income %>% 
  ggplot(aes(x = amount_mean_expense, y = amount_mean_income)) + 
  geom_point(aes(color = cluster, shape = cluster), alpha = 0.7, size = 3) +
  theme_bw()

```

### Expense vs Income vs Freq Expense

```{r}
#---- expense + income + number_expense----

#---- * number clusters ----

n_cluster_expense_income2 <-   map(.x = c("silhouette", "wss", "gap_stat"),
      .f = ~fviz_nbclust(db_train_pad %>% 
                           select(count_transactions_expense, amount_mean_income, amount_mean_expense) %>% 
                           na.omit(),
                         kmeans,
                         .x)
  )

plot_grid(n_cluster_expense_income2[[1]] + labs(title = "Silhouette"),
          n_cluster_expense_income2[[2]] + labs(title = "Elbow"),
          n_cluster_expense_income2[[3]] + labs(title = "Gap"), nrow = 1)
``` 

```{r}

#---- * clusters ----
cluster_expense_income2 <- db_train %>% 
  select(count_transactions_expense, amount_mean_expense, amount_mean_income) %>% 
  na.omit() %>% 
  mutate_if(is.numeric, ~((. - mean(.))/sd(.))) %>% 
  kmeans(centers = 4, nstart = 25)


#---- * descriptive ----
db_expense_income2 <- db_train %>% 
  select(count_transactions_expense, amount_mean_expense, amount_mean_income) %>% 
  na.omit() %>% 
  mutate(
    cluster = as.factor(cluster_expense_income2$cluster)
  )

db_expense_income2 %>% 
  pivot_longer(cols = c(amount_mean_income, amount_mean_expense), names_to = 'amount', values_to = "value") %>% 
  ggplot(aes(x = count_transactions_expense, y = value)) + 
  geom_point(aes(color = cluster, shape = cluster), alpha = 1, size = 3) +
  facet_wrap(~amount, scales = "free") +
  theme_bw()


```

### Amount Type Expense

```{r}
#---- * number clusters ----

customer_with_expense <- db_train %>% 
  select(id, count_transactions_expense) %>% 
  filter(count_transactions_expense > 0) %>% 
  ungroup() %>% 
  select(id)


db_cluster_types_expense <- db_train %>% 
  inner_join(customer_with_expense, by = 'id') %>% 
  select(amount_expense, starts_with("transactions_amount")) %>% 
  mutate_at(vars(-amount_expense), ~./amount_expense) 
  #mutate_if(is.numeric, ~((. - mean(., na.rm = T))/sd(., na.rm = T))) 

n_cluster_types <- 
  map(.x = c("silhouette", "wss", "gap_stat"),
      .f = ~fviz_nbclust(db_cluster_types_expense,
                         kmeans,
                         .x)
  )

plot_grid(n_cluster_types[[1]] + labs(title = "Silhouette"),
          n_cluster_types[[2]] + labs(title = "Elbow"),
          n_cluster_types[[3]] + labs(title = "Gap"), nrow = 1)

```

```{r}
#---- * clusters ----

cluster_types <- db_cluster_types_expense %>% 
  na.omit() %>% 
  kmeans(centers = 3, nstart = 25)


#---- * descriptive ----
db_expense_types <- db_train %>% 
  inner_join(customer_with_expense, by = 'id') %>% 
  select(amount_expense, starts_with("transactions_amount")) %>% 
  mutate_at(vars(-amount_expense), ~./amount_expense) %>% 
  select(-amount_expense) %>% 
  mutate(
    cluster = as.factor(cluster_types$cluster)
  )

db_expense_types %>%
  group_by(cluster) %>% 
  summarise_all(
    list(mean = mean)
  ) 

```



### Frequency Type Expense

```{r}
#---- types_expense freq ----

#---- * number clusters ----

customer_with_expense <- db_train %>% 
  select(id, count_transactions_expense) %>% 
  filter(count_transactions_expense > 0) %>% 
  ungroup() %>% 
  select(id)


db_cluster_types_expense_fre <- db_train %>% 
  inner_join(customer_with_expense, by = 'id') %>% 
  select(count_transactions_expense, starts_with("n_transactions")) %>% 
  mutate_at(vars(-count_transactions_expense), ~./count_transactions_expense) 
#mutate_if(is.numeric, ~((. - mean(., na.rm = T))/sd(., na.rm = T))) 

n_cluster_types_freq <- 
  map(.x = c("silhouette", "wss", "gap_stat"),
      .f = ~fviz_nbclust(db_cluster_types_expense_fre,
                         kmeans,
                         .x)
  )

plot_grid(n_cluster_types_freq[[1]] + labs(title = "Silhouette"),
          n_cluster_types_freq[[2]] + labs(title = "Elbow"),
          n_cluster_types_freq[[3]] + labs(title = "Gap"), nrow = 1)

```

```{r}

#---- * clusters ----

cluster_types <- db_cluster_types_expense_fre %>% 
  na.omit() %>% 
  kmeans(centers = 3, nstart = 25)


#---- * descriptive ----
db_expense_types_freq <- db_train %>% 
  inner_join(customer_with_expense, by = 'id') %>% 
  select(count_transactions_expense, starts_with("n_transactions")) %>% 
  mutate_at(vars(-count_transactions_expense), ~./count_transactions_expense) %>% 
  select(-count_transactions_expense) %>% 
  mutate(
    cluster = as.factor(cluster_types$cluster)
  )

db_expense_types_freq %>%
  group_by(cluster) %>% 
  summarise_all(
    list(mean = mean)
  ) 

```


# Conclusion


# Notes

This take home assignment was very challenging because it's a open problem and I could have a lot of different ways to do the analysis, My choice was explore the RFM customer behavior and at the end just FM. 


I choose to explore just one method of clustering to made things simple. But in a work day problem I would test some other method like hierarchical clustering and principally density based clustering like Dbscan and Hdbscan, because this methods has the advantage of not classifing some data points with the ideia of "Not all customers belongs a cluster".


I would like to thank the Origin team for dedicate time to elaborate this problem and give me the chance show my work.